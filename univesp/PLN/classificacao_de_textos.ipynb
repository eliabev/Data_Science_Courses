{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "\n",
    "z.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       5572 non-null   object\n",
      " 1   1       5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_table('SMSSpamCollection', header=None, encoding='UTF-8')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ham\n",
       "1        ham\n",
       "2       spam\n",
       "3        ham\n",
       "4        ham\n",
       "        ... \n",
       "5567    spam\n",
       "5568     ham\n",
       "5569     ham\n",
       "5570     ham\n",
       "5571     ham\n",
       "Name: 0, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = df[0]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point,\n",
      "crazy..\n",
      "buffet...\n",
      "wat...\n",
      "lar...\n",
      "oni...\n",
      "2\n",
      "21st\n",
      "2005.\n",
      "87121\n",
      "question(std\n",
      "rate)T&C's\n",
      "08452810075over18's\n",
      "hor...\n",
      "say...\n",
      "usf,\n",
      "3\n",
      "back!\n",
      "still?\n",
      "ok!\n",
      "send,\n",
      "£1.50\n",
      "me.\n",
      "patent.\n",
      "(Oru\n",
      "Vettam)'\n",
      "Callers.\n",
      "*9\n",
      "WINNER!!\n",
      "£900\n",
      "reward!\n",
      "09061701461.\n",
      "KL341.\n",
      "12\n",
      "only.\n",
      "11\n",
      "more?\n",
      "Free!\n",
      "08002986030\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(r'[\\d@_!#$%&^*()<>?/|{}~:\\\\/,.;?!]')\n",
    "text_messages = df[1]\n",
    "messages = text_messages[0:10]\n",
    "for line in messages:\n",
    "    words = line.split(' ')\n",
    "    for word in words:\n",
    "        if re.search(pattern, word):\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_lines = text_messages.str.lower()\n",
    "patterns = [\n",
    "    # Substituir endereços de email por 'emailaddress'\n",
    "    (r'^.+@[^\\.].*\\.[a-z]{2,}$', 'emailaddress'),\n",
    "    # Substituir URLs por 'webaddress'\n",
    "    (r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "    'webaddress'),\n",
    "    # Substituir símbolos monetários (Dólar e Euro) por 'moneysymb'\n",
    "    (r'£|\\$', 'moneysymb'),\n",
    "    # Substituir números de telefone por 'phonenumbr'\n",
    "    (r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$', 'phonenumbr'),\n",
    "    # Substituir números por 'numbr'\n",
    "    (r'\\d+(\\.\\d+)?', 'numbr'),\n",
    "    # Remover pontuação (! ?)\n",
    "    (r'[^\\w\\d\\s]', ' '),\n",
    "    # Substitua dois ou mais espaços em branco por um único espaço\n",
    "    (r'\\s+', ' '),\n",
    "    # Remova os espaços em branco à esquerda e à direita\n",
    "    (r'^\\s+|\\s+?$', '')\n",
    "]\n",
    "# Substituir no texto os padrões encontrados\n",
    "for pattern, new_word in patterns:\n",
    "    processed_lines = processed_lines.str.replace(pattern, new_word, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       go until jurong point, crazy.. available only ...\n",
       "1                           ok lar... joking wif u oni...\n",
       "2       free entry in 2 a wkly comp to win fa cup fina...\n",
       "3       u dun say so early hor... u c already then say...\n",
       "4       nah i don't think he goes to usf, he lives aro...\n",
       "                              ...                        \n",
       "5567    this is the 2nd time we have tried 2 contact u...\n",
       "5568                 will ü b going to esplanade fr home?\n",
       "5569    pity, * was in mood for that. so...any other s...\n",
       "5570    the guy did some bitching but i acted like i'd...\n",
       "5571                           rofl. its true to its name\n",
       "Name: 1, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_messages.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/eliabe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/eliabe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/eliabe/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "ps = PorterStemmer()\n",
    "for i in range(len(processed_lines)):\n",
    "    word_tokens = word_tokenize(processed_lines[i])\n",
    "    filtered_sentence = []\n",
    "\n",
    "    for word in word_tokens:\n",
    "        if word not in stop_words:\n",
    "            stemmed_word = ps.stem(word)\n",
    "            filtered_sentence.append(stemmed_word)\n",
    "    \n",
    "    processed_lines[i] = ' '.join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de palavras: 6577\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "\n",
    "for line in processed_lines:\n",
    "    word_tokens = word_tokenize(line)\n",
    "    for word in word_tokens:\n",
    "        all_words.append(word)\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "print(f'Total de palavras: {len(all_words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palavras mais comuns: [('numbr', 2648), ('u', 1207), ('call', 674), ('go', 456), ('get', 451), ('ur', 391), ('gt', 318), ('lt', 316), ('come', 304), ('moneysymbnumbr', 303)]\n",
      "Lista de características: ['go', 'jurong', 'point', 'crazi', 'avail', 'bugi', 'n', 'great', 'world', 'la']\n"
     ]
    }
   ],
   "source": [
    "print(f'Palavras mais comuns: {all_words.most_common(10)}')\n",
    "word_features = list(all_words.keys())[0:1500]\n",
    "\n",
    "print(f'Lista de características: {word_features[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "bin_labels = encoder.fit_transform(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = list(zip(processed_lines, bin_labels))\n",
    "seed = 1\n",
    "np.random.seed = seed\n",
    "\n",
    "np.random.shuffle(messages)\n",
    "features_sets = []\n",
    "for text, label in messages:\n",
    "    word_tokens = word_tokenize(text)\n",
    "    features = {}\n",
    "\n",
    "    for word in word_features:\n",
    "        features[word] = (word in word_tokens)\n",
    "    \n",
    "    features_sets.append((features, label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4179\n",
      "1393\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training, testing = train_test_split(\n",
    "    features_sets,\n",
    "    train_size=None,\n",
    "    test_size=0.25,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "print(len(training))\n",
    "print(len(testing))\n",
    "\n",
    "test_features, test_labels = zip(*testing)\n",
    "train_features, train_labels = zip(*training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros do MultinomialMB\n",
    "\n",
    "* **alpha**: float e opcional. Valor default é 0. É um aditivo (Laplace/Lidston) de suavização\n",
    "* **fit_prior**: bool opcional. Valor default é True. Indica se os valores iniciais das probabilidades devem ser ajustados de acordo com os dados de treinamento.\n",
    "* **class_prior**: array com tamanho das classes. Define a probabilidade das classes anteriores. Se especificado, os 'priores' nã são ajustados de acordo cm os dados.\n",
    "\n",
    "Como a classe precisa receber dados em fomato de matriz, precisamos adaptar o dados de *train_features* e *train_test*. Para isso, usamos a classe ***DictVectorizer***, da biblioteca ***feature_extraction***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vect = DictVectorizer(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = vect.fit_transform(train_features)\n",
    "test_features = vect.fit_transform(test_features)\n",
    "\n",
    "model = MultinomialNB(alpha=1, fit_prior=True, class_prior=None)\n",
    "\n",
    "model.fit(train_features, train_labels)\n",
    "predicted = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando matriz de confusão para avaliar o modelo de predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Predito</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Real</th>\n",
       "      <th>spam</th>\n",
       "      <td>1201</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>10</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predito     \n",
       "             spam  ham\n",
       "Real spam    1201   17\n",
       "     ham       10  165"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confus_matrix = confusion_matrix(test_labels, predicted)\n",
    "\n",
    "pd.DataFrame(\n",
    "    confus_matrix,\n",
    "    index = [['Real', 'Real'], ['spam', 'ham']],\n",
    "    columns = [['Predito', 'Predito'], ['spam', 'ham']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando relatório de qualidade do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.991742</td>\n",
       "      <td>0.986043</td>\n",
       "      <td>0.988884</td>\n",
       "      <td>1218.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>0.906593</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.924370</td>\n",
       "      <td>175.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.980617</td>\n",
       "      <td>0.980617</td>\n",
       "      <td>0.980617</td>\n",
       "      <td>0.980617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.949168</td>\n",
       "      <td>0.964450</td>\n",
       "      <td>0.956627</td>\n",
       "      <td>1393.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.981045</td>\n",
       "      <td>0.980617</td>\n",
       "      <td>0.980779</td>\n",
       "      <td>1393.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "spam           0.991742  0.986043  0.988884  1218.000000\n",
       "ham            0.906593  0.942857  0.924370   175.000000\n",
       "accuracy       0.980617  0.980617  0.980617     0.980617\n",
       "macro avg      0.949168  0.964450  0.956627  1393.000000\n",
       "weighted avg   0.981045  0.980617  0.980779  1393.000000"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(\n",
    "    test_labels,\n",
    "    predicted,\n",
    "    target_names=['spam', 'ham'],\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
